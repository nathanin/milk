# Main experiment

The set up is to test various configurations of MIL functions and encoders:

- `train_tpu_inmemory.py` runs the training, using command line flags to control the type of experiment.
    - `--mil` : one of `attention`, `average`, `instance`

Refer to `batch_train.sh` for various examples.

The main experiments are:

| # | MIL type | Encoder |
|---|-----------|---------|
| 1 | attention | pretrained |
| 2 | average | pretrained |
| 3 | instance | pretrained |
| 4 | attention | de novo |
| 5 | attention | frozen |

We'll keep track of it all with a directory structure, where individual runs are tracked by timestamp.
In addition, we record the `args` namespace generated by `argparse` for each run, and use it as a dummy-proof way to run tests afeter batch training is done (see `batch_test.sh` and `batch_test.py`).
```
experiment/
|____ args/             # arguments passed to train*
|____ test_lists/       # lists of npy keys for training
|____ val_lists/        # lists of npy keys used for validation
|____ save/             # keras saved models (h5 format)
|____ results_*/        # storage for experiment results
```
